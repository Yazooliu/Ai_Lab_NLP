{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright private in 2018 \n",
    "#  Modify Date: \n",
    "#      2018-9-30 \n",
    "#  Purpose : \n",
    "#      1. Jieba 分词\n",
    "#      2. Remove stopwords\n",
    "#      3. LDA 模型  \n",
    "#      4. TF-IDF 关键字提取\n",
    "#      5. CountVectorizer/TfidfVectorizer 构造词向量 + NavieBayesClassifier  \n",
    "# ----------\n",
    "#coding:utf-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading news data from local csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>contenttitle</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://news.sohu.com/20120612/n345428229.shtml</td>\n",
       "      <td>公安机关销毁１０余万非法枪支　跨国武器走私渐起</td>\n",
       "      <td>中广网唐山６月１２日消息（记者汤一亮　庄胜春）据中国之声《新闻晚高峰》报道，今天（１２日）上...</td>\n",
       "      <td>社会</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://news.sohu.com/20120607/n344998325.shtml</td>\n",
       "      <td>张绍刚发道歉信网友不认可：他的问题是俯视他人（图）</td>\n",
       "      <td>天津卫视求职节目《非你莫属》“晕倒门”事件余波未了，主持人张绍刚前日通过《非你莫属》节目组发...</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://news.sohu.com/20120604/n344745879.shtml</td>\n",
       "      <td>＃（关注夏收）（３）夫妻“麦客”忙麦收</td>\n",
       "      <td>临沂（山东），２０１２年６月４日　夫妻“麦客”忙麦收　６月４日，在山东省临沂市郯城县郯城街道...</td>\n",
       "      <td>农业</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://news.sohu.com/20120613/n345535702.shtml</td>\n",
       "      <td>欧洲杯大战在即　荷兰葡萄牙面临淘汰将背水一战</td>\n",
       "      <td>中广网北京６月１３日消息（记者王宇）据中国之声《新闻晚高峰》报道，明天凌晨两场欧洲杯的精彩比...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://news.sohu.com/20120601/n344598651.shtml</td>\n",
       "      <td>扎克伯格携妻罗马当街吃３０元麦当劳午餐（组图）</td>\n",
       "      <td>环球网记者李亮报道，正在意大利度蜜月的“脸谱”创始人扎克伯格与他华裔妻子的一举一动都处于媒体...</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              url               contenttitle  \\\n",
       "0  http://news.sohu.com/20120612/n345428229.shtml    公安机关销毁１０余万非法枪支　跨国武器走私渐起   \n",
       "1  http://news.sohu.com/20120607/n344998325.shtml  张绍刚发道歉信网友不认可：他的问题是俯视他人（图）   \n",
       "2  http://news.sohu.com/20120604/n344745879.shtml        ＃（关注夏收）（３）夫妻“麦客”忙麦收   \n",
       "3  http://news.sohu.com/20120613/n345535702.shtml     欧洲杯大战在即　荷兰葡萄牙面临淘汰将背水一战   \n",
       "4  http://news.sohu.com/20120601/n344598651.shtml    扎克伯格携妻罗马当街吃３０元麦当劳午餐（组图）   \n",
       "\n",
       "                                             content category  \n",
       "0  中广网唐山６月１２日消息（记者汤一亮　庄胜春）据中国之声《新闻晚高峰》报道，今天（１２日）上...       社会  \n",
       "1  天津卫视求职节目《非你莫属》“晕倒门”事件余波未了，主持人张绍刚前日通过《非你莫属》节目组发...       娱乐  \n",
       "2  临沂（山东），２０１２年６月４日　夫妻“麦客”忙麦收　６月４日，在山东省临沂市郯城县郯城街道...       农业  \n",
       "3  中广网北京６月１３日消息（记者王宇）据中国之声《新闻晚高峰》报道，明天凌晨两场欧洲杯的精彩比...       体育  \n",
       "4  环球网记者李亮报道，正在意大利度蜜月的“脸谱”创始人扎克伯格与他华裔妻子的一举一动都处于媒体...       科技  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news =  pd.read_csv('./data/news.csv',names = ['url','contenttitle','content','category'],encoding = 'utf-8')\n",
    "df_news =  df_news.dropna()\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_news.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中广网北京６月１３日消息（记者王宇）据中国之声《新闻晚高峰》报道，明天凌晨两场欧洲杯的精彩比赛上演，死亡之组Ｂ组当中两支传统的强队荷兰队和葡萄牙队正面临着提前淘汰出局的危险。第一轮之后Ｂ组的积分的形势是３、３、０、０，德国和丹麦３分，葡萄牙和荷兰０分。今天又是３分的两支球队分别对阵０分的两支球队，如果０分的再输就会被淘汰，而３分的如果再赢就可以提前出线。换句话说，德国和丹麦今天晚上赢球就能出线，葡萄牙和荷兰如果输球就要回家。葡萄牙：Ｃ罗输球后失声痛哭北京时间今天晚上１２点丹麦对葡萄牙的比赛将在乌克兰的利沃夫进行，明天凌晨２点４５分德国对荷兰的比赛将在乌克兰的哈尔科夫进行。在输球就要回家的阴影笼罩之下，荷兰和葡萄牙队身上的压力可想而知。第一轮比赛中葡萄牙队负于德国。不过德国的实力强于葡萄牙强，葡萄牙队受到的质疑并不算大，但是头号球星罗纳尔多对自己的要求非常严格，现在全队的压力有七成都集中在了罗纳尔多身上，他想在国家队证明自己的欲望也非常强烈。虽然据说输球之后他甚至失声痛哭，但他后来表示在与皇马的教练穆里尼奥谈过之后，他相信葡萄牙队一定能够赢得这场球，带领球队走出困境。荷兰：媒体曝球队＂内讧＂和葡萄牙队相比，荷兰队在第一场输球以后产生的负能量更多一些。早在和丹麦队比赛之前就有媒体传出荷兰队出现了内讧，核心的人物就是范佩西和亨特拉尔这两名主力前锋的竞争者。而输给丹麦之后矛盾越来越多，涉及到的人也越来越多，有球员和球员之间的，也有球员和教练之间的。亨特拉尔对自己不能首发上场不满意，范德法特也抵触替补的角色，中场的德容质疑主帅是任人唯亲，在第一场里边把自己提前换下去没有把自己的女婿范博梅尔提前换下去。对于这样种种的矛盾，中场大将斯内德表示队中确实有人太过于自我，承认目前球队的气氛不如两年前，但是他也认为输掉第一场比赛之后出现这样的情况是正常的，但是不管怎么说如果荷兰想要战胜强大的德国队，必须先整理好内部。对于球迷来说，今天晚上的比赛会非常有吸引力，在荷兰和葡萄牙必须赢球的情况下，死亡之组的比赛将不会像首轮那样沉闷，一定会精彩纷呈。\n",
      "体育\n"
     ]
    }
   ],
   "source": [
    "# content show\n",
    "content  = df_news.content.values.tolist()\n",
    "category = df_news.category.values.tolist()\n",
    "\n",
    "# print content and category\n",
    "print(content[3])\n",
    "print(category[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "体育\n"
     ]
    }
   ],
   "source": [
    "## category\n",
    "category = df_news.category.values.tolist()\n",
    "print(category[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. 分词: 使用jieba分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉换行和回车符  - \n",
    "content_S = []\n",
    "# line 表示当前新闻的一条主体\n",
    "for line in content: \n",
    "    current_segment =  jieba.lcut(line)\n",
    "    if len(current_segment) >1 and current_segment != '\\r\\n': # 不包括回车或者换行符\n",
    "        content_S.append(current_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中广网',\n",
       " '北京',\n",
       " '６',\n",
       " '月',\n",
       " '１',\n",
       " '３',\n",
       " '日',\n",
       " '消息',\n",
       " '（',\n",
       " '记者',\n",
       " '王宇',\n",
       " '）',\n",
       " '据',\n",
       " '中国',\n",
       " '之声',\n",
       " '《',\n",
       " '新闻',\n",
       " '晚',\n",
       " '高峰',\n",
       " '》',\n",
       " '报道',\n",
       " '，',\n",
       " '明天',\n",
       " '凌晨',\n",
       " '两场',\n",
       " '欧洲杯',\n",
       " '的',\n",
       " '精彩',\n",
       " '比赛',\n",
       " '上演',\n",
       " '，',\n",
       " '死亡',\n",
       " '之组',\n",
       " 'Ｂ',\n",
       " '组',\n",
       " '当中',\n",
       " '两支',\n",
       " '传统',\n",
       " '的',\n",
       " '强队',\n",
       " '荷兰队',\n",
       " '和',\n",
       " '葡萄牙队',\n",
       " '正',\n",
       " '面临',\n",
       " '着',\n",
       " '提前',\n",
       " '淘汰',\n",
       " '出局',\n",
       " '的',\n",
       " '危险',\n",
       " '。',\n",
       " '\\ue40c',\n",
       " '第一轮',\n",
       " '之后',\n",
       " 'Ｂ',\n",
       " '组',\n",
       " '的',\n",
       " '积分',\n",
       " '的',\n",
       " '形势',\n",
       " '是',\n",
       " '３',\n",
       " '、',\n",
       " '３',\n",
       " '、',\n",
       " '０',\n",
       " '、',\n",
       " '０',\n",
       " '，',\n",
       " '德国',\n",
       " '和',\n",
       " '丹麦',\n",
       " '３',\n",
       " '分',\n",
       " '，',\n",
       " '葡萄牙',\n",
       " '和',\n",
       " '荷兰',\n",
       " '０',\n",
       " '分',\n",
       " '。',\n",
       " '今天',\n",
       " '又',\n",
       " '是',\n",
       " '３',\n",
       " '分',\n",
       " '的',\n",
       " '两支',\n",
       " '球队',\n",
       " '分别',\n",
       " '对阵',\n",
       " '０',\n",
       " '分',\n",
       " '的',\n",
       " '两支',\n",
       " '球队',\n",
       " '，',\n",
       " '如果',\n",
       " '０',\n",
       " '分',\n",
       " '的',\n",
       " '再',\n",
       " '输',\n",
       " '就',\n",
       " '会',\n",
       " '被',\n",
       " '淘汰',\n",
       " '，',\n",
       " '而',\n",
       " '３',\n",
       " '分',\n",
       " '的',\n",
       " '如果',\n",
       " '再赢',\n",
       " '就',\n",
       " '可以',\n",
       " '提前',\n",
       " '出线',\n",
       " '。',\n",
       " '换句话说',\n",
       " '，',\n",
       " '德国',\n",
       " '和',\n",
       " '丹麦',\n",
       " '今天',\n",
       " '晚上',\n",
       " '赢球',\n",
       " '就',\n",
       " '能',\n",
       " '出线',\n",
       " '，',\n",
       " '葡萄牙',\n",
       " '和',\n",
       " '荷兰',\n",
       " '如果',\n",
       " '输球',\n",
       " '就要',\n",
       " '回家',\n",
       " '。',\n",
       " '\\ue40c',\n",
       " '葡萄牙',\n",
       " '：',\n",
       " 'Ｃ',\n",
       " '罗',\n",
       " '输球',\n",
       " '后',\n",
       " '失声痛哭',\n",
       " '\\ue40c',\n",
       " '北京',\n",
       " '时间',\n",
       " '今天',\n",
       " '晚上',\n",
       " '１',\n",
       " '２',\n",
       " '点',\n",
       " '丹麦',\n",
       " '对',\n",
       " '葡萄牙',\n",
       " '的',\n",
       " '比赛',\n",
       " '将',\n",
       " '在',\n",
       " '乌克兰',\n",
       " '的',\n",
       " '利沃夫',\n",
       " '进行',\n",
       " '，',\n",
       " '明天',\n",
       " '凌晨',\n",
       " '２',\n",
       " '点',\n",
       " '４',\n",
       " '５',\n",
       " '分',\n",
       " '德国',\n",
       " '对',\n",
       " '荷兰',\n",
       " '的',\n",
       " '比赛',\n",
       " '将',\n",
       " '在',\n",
       " '乌克兰',\n",
       " '的',\n",
       " '哈尔科夫',\n",
       " '进行',\n",
       " '。',\n",
       " '在',\n",
       " '输球',\n",
       " '就要',\n",
       " '回家',\n",
       " '的',\n",
       " '阴影',\n",
       " '笼罩',\n",
       " '之下',\n",
       " '，',\n",
       " '荷兰',\n",
       " '和',\n",
       " '葡萄牙队',\n",
       " '身上',\n",
       " '的',\n",
       " '压力',\n",
       " '可想而知',\n",
       " '。',\n",
       " '\\ue40c',\n",
       " '第一轮',\n",
       " '比赛',\n",
       " '中',\n",
       " '葡萄牙队',\n",
       " '负于',\n",
       " '德国',\n",
       " '。',\n",
       " '不过',\n",
       " '德国',\n",
       " '的',\n",
       " '实力',\n",
       " '强于',\n",
       " '葡萄牙',\n",
       " '强',\n",
       " '，',\n",
       " '葡萄牙队',\n",
       " '受到',\n",
       " '的',\n",
       " '质疑',\n",
       " '并',\n",
       " '不算',\n",
       " '大',\n",
       " '，',\n",
       " '但是',\n",
       " '头号',\n",
       " '球星',\n",
       " '罗纳尔多',\n",
       " '对',\n",
       " '自己',\n",
       " '的',\n",
       " '要求',\n",
       " '非常',\n",
       " '严格',\n",
       " '，',\n",
       " '现在',\n",
       " '全队',\n",
       " '的',\n",
       " '压力',\n",
       " '有',\n",
       " '七成',\n",
       " '都',\n",
       " '集中',\n",
       " '在',\n",
       " '了',\n",
       " '罗纳尔多',\n",
       " '身上',\n",
       " '，',\n",
       " '他',\n",
       " '想',\n",
       " '在',\n",
       " '国家队',\n",
       " '证明',\n",
       " '自己',\n",
       " '的',\n",
       " '欲望',\n",
       " '也',\n",
       " '非常',\n",
       " '强烈',\n",
       " '。',\n",
       " '虽然',\n",
       " '据说',\n",
       " '输球',\n",
       " '之后',\n",
       " '他',\n",
       " '甚至',\n",
       " '失声痛哭',\n",
       " '，',\n",
       " '但',\n",
       " '他',\n",
       " '后来',\n",
       " '表示',\n",
       " '在',\n",
       " '与',\n",
       " '皇马',\n",
       " '的',\n",
       " '教练',\n",
       " '穆里尼奥',\n",
       " '谈过',\n",
       " '之后',\n",
       " '，',\n",
       " '他',\n",
       " '相信',\n",
       " '葡萄牙队',\n",
       " '一定',\n",
       " '能够',\n",
       " '赢得',\n",
       " '这场',\n",
       " '球',\n",
       " '，',\n",
       " '带领',\n",
       " '球队',\n",
       " '走出',\n",
       " '困境',\n",
       " '。',\n",
       " '\\ue40c',\n",
       " '荷兰',\n",
       " '：',\n",
       " '媒体',\n",
       " '曝',\n",
       " '球队',\n",
       " '＂',\n",
       " '内讧',\n",
       " '＂',\n",
       " '\\ue40c',\n",
       " '和',\n",
       " '葡萄牙队',\n",
       " '相比',\n",
       " '，',\n",
       " '荷兰队',\n",
       " '在',\n",
       " '第一场',\n",
       " '输球',\n",
       " '以后',\n",
       " '产生',\n",
       " '的',\n",
       " '负',\n",
       " '能量',\n",
       " '更',\n",
       " '多一些',\n",
       " '。',\n",
       " '早',\n",
       " '在',\n",
       " '和',\n",
       " '丹麦队',\n",
       " '比赛',\n",
       " '之前',\n",
       " '就',\n",
       " '有',\n",
       " '媒体',\n",
       " '传出',\n",
       " '荷兰队',\n",
       " '出现',\n",
       " '了',\n",
       " '内讧',\n",
       " '，',\n",
       " '核心',\n",
       " '的',\n",
       " '人物',\n",
       " '就是',\n",
       " '范佩西',\n",
       " '和亨特',\n",
       " '拉尔',\n",
       " '这',\n",
       " '两名',\n",
       " '主力',\n",
       " '前锋',\n",
       " '的',\n",
       " '竞争者',\n",
       " '。',\n",
       " '而',\n",
       " '输给',\n",
       " '丹麦',\n",
       " '之后',\n",
       " '矛盾',\n",
       " '越来越',\n",
       " '多',\n",
       " '，',\n",
       " '涉及',\n",
       " '到',\n",
       " '的',\n",
       " '人',\n",
       " '也',\n",
       " '越来越',\n",
       " '多',\n",
       " '，',\n",
       " '有',\n",
       " '球员',\n",
       " '和',\n",
       " '球员',\n",
       " '之间',\n",
       " '的',\n",
       " '，',\n",
       " '也',\n",
       " '有',\n",
       " '球员',\n",
       " '和',\n",
       " '教练',\n",
       " '之间',\n",
       " '的',\n",
       " '。',\n",
       " '亨特',\n",
       " '拉尔',\n",
       " '对',\n",
       " '自己',\n",
       " '不能',\n",
       " '首发',\n",
       " '上场',\n",
       " '不',\n",
       " '满意',\n",
       " '，',\n",
       " '范德法',\n",
       " '特',\n",
       " '也',\n",
       " '抵触',\n",
       " '替补',\n",
       " '的',\n",
       " '角色',\n",
       " '，',\n",
       " '中场',\n",
       " '的',\n",
       " '德容',\n",
       " '质疑',\n",
       " '主帅',\n",
       " '是',\n",
       " '任人唯亲',\n",
       " '，',\n",
       " '在',\n",
       " '第一场',\n",
       " '里边',\n",
       " '把',\n",
       " '自己',\n",
       " '提前',\n",
       " '换下去',\n",
       " '没有',\n",
       " '把',\n",
       " '自己',\n",
       " '的',\n",
       " '女婿',\n",
       " '范博梅',\n",
       " '尔',\n",
       " '提前',\n",
       " '换下去',\n",
       " '。',\n",
       " '\\ue40c',\n",
       " '对于',\n",
       " '这样',\n",
       " '种种',\n",
       " '的',\n",
       " '矛盾',\n",
       " '，',\n",
       " '中场',\n",
       " '大将',\n",
       " '斯内德',\n",
       " '表示',\n",
       " '队中',\n",
       " '确实',\n",
       " '有人',\n",
       " '太',\n",
       " '过于',\n",
       " '自我',\n",
       " '，',\n",
       " '承认',\n",
       " '目前',\n",
       " '球队',\n",
       " '的',\n",
       " '气氛',\n",
       " '不如',\n",
       " '两年',\n",
       " '前',\n",
       " '，',\n",
       " '但是',\n",
       " '他',\n",
       " '也',\n",
       " '认为',\n",
       " '输掉',\n",
       " '第一场',\n",
       " '比赛',\n",
       " '之后',\n",
       " '出现',\n",
       " '这样',\n",
       " '的',\n",
       " '情况',\n",
       " '是',\n",
       " '正常',\n",
       " '的',\n",
       " '，',\n",
       " '但是',\n",
       " '不管怎么',\n",
       " '说',\n",
       " '如果',\n",
       " '荷兰',\n",
       " '想要',\n",
       " '战胜',\n",
       " '强大',\n",
       " '的',\n",
       " '德国队',\n",
       " '，',\n",
       " '必须',\n",
       " '先',\n",
       " '整理',\n",
       " '好',\n",
       " '内部',\n",
       " '。',\n",
       " '\\ue40c',\n",
       " '对于',\n",
       " '球迷',\n",
       " '来说',\n",
       " '，',\n",
       " '今天',\n",
       " '晚上',\n",
       " '的',\n",
       " '比赛',\n",
       " '会',\n",
       " '非常',\n",
       " '有',\n",
       " '吸引力',\n",
       " '，',\n",
       " '在',\n",
       " '荷兰',\n",
       " '和',\n",
       " '葡萄牙',\n",
       " '必须',\n",
       " '赢球',\n",
       " '的',\n",
       " '情况',\n",
       " '下',\n",
       " '，',\n",
       " '死亡',\n",
       " '之组',\n",
       " '的',\n",
       " '比赛',\n",
       " '将',\n",
       " '不会',\n",
       " '像',\n",
       " '首轮',\n",
       " '那样',\n",
       " '沉闷',\n",
       " '，',\n",
       " '一定',\n",
       " '会',\n",
       " '精彩纷呈',\n",
       " '。']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_S[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[中广网, 唐山, ６, 月, １, ２, 日, 消息, （, 记者, 汤一亮, 　, 庄胜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天津, 卫视, 求职, 节目, 《, 非你莫属, 》, “, 晕倒, 门, ”, 事件, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[临沂, （, 山东, ）, ，, ２, ０, １, ２, 年, ６, 月, ４, 日, 　...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[中广网, 北京, ６, 月, １, ３, 日, 消息, （, 记者, 王宇, ）, 据, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[环球网, 记者, 李亮, 报道, ，, 正在, 意大利, 度蜜月, 的, “, 脸谱, ”...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           content_S\n",
       "0  [中广网, 唐山, ６, 月, １, ２, 日, 消息, （, 记者, 汤一亮, 　, 庄胜...\n",
       "1  [天津, 卫视, 求职, 节目, 《, 非你莫属, 》, “, 晕倒, 门, ”, 事件, ...\n",
       "2  [临沂, （, 山东, ）, ，, ２, ０, １, ２, 年, ６, 月, ４, 日, 　...\n",
       "3  [中广网, 北京, ６, 月, １, ３, 日, 消息, （, 记者, 王宇, ）, 据, ...\n",
       "4  [环球网, 记者, 李亮, 报道, ，, 正在, 意大利, 度蜜月, 的, “, 脸谱, ”..."
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当前的结果\n",
    "pd_content  = pd.DataFrame( {'content_S':content_S} )\n",
    "pd_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 去掉stopswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010,?、。“”《》！，：；？.........。。。。。。。。。123457890下一...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           stopwords\n",
       "0  2010,?、。“”《》！，：；？.........。。。。。。。。。123457890下一..."
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords Show \n",
    "\n",
    "stopwords = pd.read_csv(\"./data/stopwords.txt\",index_col = False, sep = \"\\t\",quoting = 3, names = ['stopwords'],encoding= 'utf-8')\n",
    "stopwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words functions \n",
    "def remove_stopwords(contents,stopwords):\n",
    "    \n",
    "    content_clean = []  # content that removed stopward \n",
    "    all_words     = []  # all word removed stopwords\n",
    "    for line in contents:\n",
    "        line_clean = []  # every line that removed stopwords \n",
    "         \n",
    "        for word in line:\n",
    "            if word in stopwords:\n",
    "                continue             # 如果 word 出现stop words 里面， 则继续执行。跳过\n",
    "            line_clean.append(word)  # 否则认为是好的词加到line_clean 中\n",
    "            all_words.append(str(word))\n",
    "        content_clean.append(line_clean)\n",
    "    return all_words,content_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call remove_stopwords to remove stop words\n",
    "\n",
    "contents  = pd_content.content_S.values.tolist()\n",
    "#stopwords = stopwords.stopwords.values.tolist()\n",
    "all_words,content_clean = remove_stopwords(contents,stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[中广网, 唐山, ６, 月, １, ２, 日, 消息, （, 记者, 汤一亮, 　, 庄胜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天津, 卫视, 求职, 节目, 《, 非你莫属, 》, “, 晕倒, 门, ”, 事件, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[临沂, （, 山东, ）, ，, ２, ０, １, ２, 年, ６, 月, ４, 日, 　...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[中广网, 北京, ６, 月, １, ３, 日, 消息, （, 记者, 王宇, ）, 据, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[环球网, 记者, 李亮, 报道, ，, 正在, 意大利, 度蜜月, 的, “, 脸谱, ”...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       content_clean\n",
       "0  [中广网, 唐山, ６, 月, １, ２, 日, 消息, （, 记者, 汤一亮, 　, 庄胜...\n",
       "1  [天津, 卫视, 求职, 节目, 《, 非你莫属, 》, “, 晕倒, 门, ”, 事件, ...\n",
       "2  [临沂, （, 山东, ）, ，, ２, ０, １, ２, 年, ６, 月, ４, 日, 　...\n",
       "3  [中广网, 北京, ６, 月, １, ３, 日, 消息, （, 记者, 王宇, ）, 据, ...\n",
       "4  [环球网, 记者, 李亮, 报道, ，, 正在, 意大利, 度蜜月, 的, “, 脸谱, ”..."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# content that remove stopwords\n",
    "pd_content  = pd.DataFrame({'content_clean':content_clean})\n",
    "pd_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>中广网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>唐山</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>６</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>月</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>１</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_words\n",
       "0       中广网\n",
       "1        唐山\n",
       "2         ６\n",
       "3         月\n",
       "4         １"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_words \n",
    "df_all_words  = pd.DataFrame({'all_words':all_words})\n",
    "df_all_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\h155809\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>，</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>的</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>。</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>、</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>１</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     all_words  count\n",
       "1668         ，    327\n",
       "1173         的    183\n",
       "8            。    128\n",
       "7            、     80\n",
       "1671         １     68"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "words_count = df_all_words.groupby(by = ['all_words'])['all_words'].agg({\"count\":numpy.size})\n",
    "\n",
    "# 按照值进行排序 - reset_index\n",
    "words_count =words_count.reset_index().sort_values(by = [\"count\"],ascending = False)\n",
    "\n",
    "words_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.LDA 主题模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 TF-IDF 关键字提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环球网记者李亮报道，正在意大利度蜜月的“脸谱”创始人扎克伯格与他华裔妻子的一举一动都处于媒体的追踪之下。５月３１日，在罗马这个拥有１３家米其林星级餐厅的城市，身家近千亿的扎克伯格夫妇被发现穿着普通的Ｔ恤短袖，在路边一家麦当劳花３英镑买了两人的午餐，并坐在街边的台阶上大嚼起来。英国《每日电讯报》５月３１日报道，扎克伯格夫妇的这顿午饭包括汉堡、炸鸡，仅３英镑（约为人民币３０元）。两人先是依偎着看餐牌，然后由妻子点餐，扎克伯格则调皮地拿起手机，给妻子拍照。拎着装满快餐食品的纸袋子，这对明星夫妇竟坐在街边的一个台阶上，边聊天边大吃起来。一位路人告诉记者，“没人认出他们俩。他们只是混在人群中。”延伸阅读：网友在微博上热传，ＣＣＴＶ最近播出的纪录片《中国警察》中，一位疑似脸谱网站创始人扎克伯格的群众演员成最大牌的“路人甲”。据报道，《中国警察》第四集第３１秒左右，出现貌似扎克伯格及其妻子今年３月在上海游玩时候的镜头。对着镜头，“扎克伯格”似乎笑得很开心，走路一甩一甩的让网友大呼喜感。［详细］（中国新闻网）\n",
      "关键字：\n",
      "扎克 伯格 妻子 夫妇\n"
     ]
    }
   ],
   "source": [
    "#df_news =  pd.read_csv('C:/Python_/data/news.csv',names = ['url','contenttitle','content'],encoding = 'utf-8')\n",
    "#df_news =  df_news.dropna()\n",
    "#df_news.head()\n",
    "\n",
    "import jieba.analyse\n",
    "index = 4\n",
    "print (df_news['content'][index])\n",
    "content_S_str = \"\".join(content_S[index])\n",
    "\n",
    "print(\"关键字：\")\n",
    "print (\" \".join(jieba.analyse.extract_tags(content_S_str,topK = 4, withWeight = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LDA 主题模型\n",
    "#### 主题中有哪些关键词，以及关键词出现的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 格式： list of list  分词好的整个语料\n",
    "## 一篇文章当中，有哪些,主题中哪些关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora,models,similarities ## 语料库。模型.相似度\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 做映射，要提前分好词\n",
    "dictionary  = corpora.Dictionary(content_clean) # 将词语映射成模型\n",
    "corpus  =[dictionary.doc2bow(sentence) for sentence in content_clean ]\n",
    "\n",
    "###Lda \n",
    "lda = gensim.models.ldamodel.LdaModel(corpus = corpus, id2word = dictionary , num_topics = 12) # num_topics 多少个主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042*\"，\" + 0.017*\"的\"\n"
     ]
    }
   ],
   "source": [
    "## 11 号分类结果\n",
    "print (lda.print_topic(11,topn = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.062*\"，\" + 0.027*\"的\"\n",
      "0.009*\"，\" + 0.009*\"”\"\n",
      "0.030*\"，\" + 0.020*\"的\"\n",
      "0.027*\"的\" + 0.024*\"，\"\n",
      "0.050*\"，\" + 0.038*\"的\"\n",
      "0.052*\"，\" + 0.029*\"的\"\n",
      "0.045*\"，\" + 0.028*\"的\"\n",
      "0.032*\"，\" + 0.016*\"的\"\n",
      "0.040*\"，\" + 0.030*\"的\"\n",
      "0.039*\"，\" + 0.019*\"１\"\n",
      "0.075*\"，\" + 0.037*\"的\"\n",
      "0.042*\"，\" + 0.017*\"的\"\n",
      "明显stopwords 没有work\n"
     ]
    }
   ],
   "source": [
    "##print all kinds of toptic \n",
    "for topic in lda.print_topics(num_topics = 12, num_words =2):\n",
    "    print (topic[1])\n",
    "\n",
    "# Issue \n",
    "print(\"明显stopwords 没有work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 新闻文本分类任务\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[中广网, 唐山, ６, 月, １, ２, 日, 消息, （, 记者, 汤一亮, 　, 庄胜...</td>\n",
       "      <td>社会</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天津, 卫视, 求职, 节目, 《, 非你莫属, 》, “, 晕倒, 门, ”, 事件, ...</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[临沂, （, 山东, ）, ，, ２, ０, １, ２, 年, ６, 月, ４, 日, 　...</td>\n",
       "      <td>农业</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[中广网, 北京, ６, 月, １, ３, 日, 消息, （, 记者, 王宇, ）, 据, ...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[环球网, 记者, 李亮, 报道, ，, 正在, 意大利, 度蜜月, 的, “, 脸谱, ”...</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[本报记者, 　, 张忠德, , 本报, 通讯员, 　, 张艳, 　, 苏婧, , 城区...</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[中新网, ６, 月, ８, 日电, 　, 据, 朝中社, 报道, ，, ２, ６, ０, ...</td>\n",
       "      <td>国际</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[中新社, 北京, ６, 月, ２, 日电, （, 记者, 　, 刘辰瑶, ）, 国资委, ...</td>\n",
       "      <td>民生</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[证监会, 近日, 召开, 新闻, 通气会, ，, 就, 《, 关于, 加强, 与, 上市公...</td>\n",
       "      <td>经济</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[中国台湾, 网, ６, 月, １, ５, 日, 消息, 　, 据, 台湾, 《, 中国时报...</td>\n",
       "      <td>文化</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[受到, 欧美, 股市, 大跌, 以及, 多, 部位, 联合, 吹风, 设立, 国际, 板,...</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[中新网, ６, 月, １, 日电, 　, 据, 台湾, “, 中央社, ”, 报道, ，,...</td>\n",
       "      <td>政治</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        content_clean label\n",
       "0   [中广网, 唐山, ６, 月, １, ２, 日, 消息, （, 记者, 汤一亮, 　, 庄胜...    社会\n",
       "1   [天津, 卫视, 求职, 节目, 《, 非你莫属, 》, “, 晕倒, 门, ”, 事件, ...    娱乐\n",
       "2   [临沂, （, 山东, ）, ，, ２, ０, １, ２, 年, ６, 月, ４, 日, 　...    农业\n",
       "3   [中广网, 北京, ６, 月, １, ３, 日, 消息, （, 记者, 王宇, ）, 据, ...    体育\n",
       "4   [环球网, 记者, 李亮, 报道, ，, 正在, 意大利, 度蜜月, 的, “, 脸谱, ”...    科技\n",
       "5   [本报记者, 　, 张忠德, , 本报, 通讯员, 　, 张艳, 　, 苏婧, , 城区...    娱乐\n",
       "6   [中新网, ６, 月, ８, 日电, 　, 据, 朝中社, 报道, ，, ２, ６, ０, ...    国际\n",
       "7   [中新社, 北京, ６, 月, ２, 日电, （, 记者, 　, 刘辰瑶, ）, 国资委, ...    民生\n",
       "8   [证监会, 近日, 召开, 新闻, 通气会, ，, 就, 《, 关于, 加强, 与, 上市公...    经济\n",
       "9   [中国台湾, 网, ６, 月, １, ５, 日, 消息, 　, 据, 台湾, 《, 中国时报...    文化\n",
       "10  [受到, 欧美, 股市, 大跌, 以及, 多, 部位, 联合, 吹风, 设立, 国际, 板,...    金融\n",
       "11  [中新网, ６, 月, １, 日电, 　, 据, 台湾, “, 中央社, ”, 报道, ，,...    政治"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train  =  pd.DataFrame({'content_clean':content_clean, 'label':df_news['category']})\n",
    "#df_train.head()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.所有的标签label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['社会', '娱乐', '农业', '体育', '科技', '国际', '民生', '经济', '文化', '金融', '政治'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有的label\n",
    "df_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 将label 值全部替换成数字，因为计算机只能读懂数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content_Clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[中广网, 唐山, ６, 月, １, ２, 日, 消息, （, 记者, 汤一亮, 　, 庄胜...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天津, 卫视, 求职, 节目, 《, 非你莫属, 》, “, 晕倒, 门, ”, 事件, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[临沂, （, 山东, ）, ，, ２, ０, １, ２, 年, ６, 月, ４, 日, 　...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[中广网, 北京, ６, 月, １, ３, 日, 消息, （, 记者, 王宇, ）, 据, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[环球网, 记者, 李亮, 报道, ，, 正在, 意大利, 度蜜月, 的, “, 脸谱, ”...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Content_Clean  label\n",
       "0  [中广网, 唐山, ６, 月, １, ２, 日, 消息, （, 记者, 汤一亮, 　, 庄胜...      1\n",
       "1  [天津, 卫视, 求职, 节目, 《, 非你莫属, 》, “, 晕倒, 门, ”, 事件, ...      2\n",
       "2  [临沂, （, 山东, ）, ，, ２, ０, １, ２, 年, ６, 月, ４, 日, 　...      3\n",
       "3  [中广网, 北京, ６, 月, １, ３, 日, 消息, （, 记者, 王宇, ）, 据, ...      4\n",
       "4  [环球网, 记者, 李亮, 报道, ，, 正在, 意大利, 度蜜月, 的, “, 脸谱, ”...      5"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {\"社会\":1,\"娱乐\":2,\"农业\":3,\"体育\":4,\"科技\":5, \"国际\":6, \"民生\":7,\"经济\":8,\"文化\":9,\"金融\":10,\"政治\":11}\n",
    "\n",
    "df_train['label'] = df_train['label'].map(label_mapping)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train _test _split \n",
    "# content as the trian data, label as the standard values of prediction \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train,x_test,y_train,y_test  = train_test_split(df_train['content_clean'].values,df_train['label'].values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list to string  for data\n",
    "def word_tostring(data):\n",
    "    \n",
    "    words_train = []\n",
    "    for line_index in range(len(data)):\n",
    "        try: # 记录程序执行的异常\n",
    "            words_train.append(' '.join(x_train[line_index]))  #  将array中的文字，按照空格连接成字符串\n",
    "        except:\n",
    "                print ( \"exception warning :\", line_index, word_index)\n",
    "    return words_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(words_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'cat', 'cat cat', 'dog', 'dog cat', 'dog cat cat', 'dog fish', 'dog fish cat', 'fish', 'fish bird', 'fish cat']\n",
      "[[0 1 0 1 0 0 1 1 1 0 1]\n",
      " [0 2 1 1 1 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 1 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Domo -show to constrct vector \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "texts = [\"dog fish cat\",\"dog cat cat \",\" fish bird\",\"bird\"]\n",
    "\n",
    "cv     = CountVectorizer(ngram_range = (1,4)) # n garm = 1,2,3\n",
    "cv_fit = cv.fit_transform(texts)\n",
    "\n",
    "print(cv.get_feature_names()) \n",
    "\n",
    "print(cv_fit.toarray()) # 按照上述打印的类型，将texts中的字符按照数量转换成向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "print( cv_fit.toarray().sum(axis = 0) )  # 0 - 按照列求和。 1——按照行数求和\n",
    "\n",
    "# bird = 2, cat = 3, dog = 2, fish  = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=10, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 按照词来构造向量\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "vec = CountVectorizer(analyzer = 'word', max_features = 10, lowercase = False)\n",
    "words_train = word_tostring(x_train)\n",
    "vec.fit(words_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vec.transform(words_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. navie 贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 构成 Navie 贝叶斯分类器\n",
    "from  sklearn.naive_bayes import MultinomialNB\n",
    "classifier  = MultinomialNB()\n",
    "classifier.fit(vec.transform(words_train),y_train)  # vec.transform(words) 转words 为向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(words_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data train to join to string\n",
    "words_test = word_tostring(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'中国台湾 网 ６ 月 １ ５ 日 消息 \\u3000 据 台湾 《 中国时报 》 报道 ， 岛内 大学教授 “ 假发票 、 真 Ａ 钱 ” 案 ， 如 滚雪球 ， 愈演愈烈 ， 目前 共有 台北 、 台 中 、 彰化 、 台南 等 四个 地检署 在 侦办 。 最新 一期 的 《 时报周刊 》 报道 ， 涉案 教授 可能 多达 １ ０ ０ ０ 人 ， 其中 理工 领域 占 三分之二 强 ； 由于 台湾 “ 检察 总长 ” 黄世铭 定调 以 贪污罪 嫌 究办 ， 涉案者 将 面临 牢狱之灾 ， 岛内 各 顶尖 大学 或 学生 ， 都 会 产生 不小 冲击 。 （ 中国台湾 网 \\u3000 刘海 伟 ）'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.score(vec.transform(words_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.TF - IDF + Naive 贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=10, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造向量\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "Tfidfclassifier = TfidfVectorizer(analyzer = 'word', max_features = 10, lowercase = False)\n",
    "Tfidfclassifier.fit(words_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier  = MultinomialNB()\n",
    "classifier.fit(vec.transform(words_train),y_train)  # vec.transform(words) 转words 为向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(words_train),y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
